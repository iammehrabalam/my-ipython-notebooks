{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<center><h1><u>Opinion or Sentiment analysis on online Product Reviews</h1></u></center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2><span style=\"color:blue\">AIM:</span> <b>To generate the polarity (Negative or Positive) of  Online Product Reviews</b></h2>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<center><h2><u>Our Approaches</u></h2></center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<ol>\n",
      "    <li>\n",
      "        <h3 style=\"color:red\">Bag of Word Concept ( Unigram modeling ) </h3>\n",
      "        <center style=\"font-size:16px\"><h2><u>Algorithm</u></h2></center>\n",
      "        <h2>1. Text Pre-Processing</h2>\n",
      "            <ul>\n",
      "                <h3><li>Extracting Emoticons and replace it with word </li></h3>\n",
      "            </ul>\n",
      "        <h2>2. Text Refinement</h2>\n",
      "            <ul>\n",
      "                <h3><li>Remove all stopwords and all other irrelevant from documents</li></h3>\n",
      "                <h3><li>Tokenize documents into words and consider it as features</li></h3>\n",
      "            </ul>\n",
      "        <h2>3.Learning</h2>\n",
      "            <ul>\n",
      "                <h3>\n",
      "                   <li>Normalize Count matrix of document using Tf-Idf (Term frequency\u2013Inverse document frequency) method </li>\n",
      "                </h3>\n",
      "                <h3><li>Use Naive Bayes / multinomial Naive Bayes classifier</li></h3>\n",
      "           </ul>\n",
      "           <center>\n",
      "               <h2 style=\"color:red\">Problem</h2>\n",
      "               <h3 >\n",
      "               Feature vector size is to large (about 20,000) and also content not sentimental words like\n",
      "               <u style=\"color:red\">about, would, android, anything, apple, apply, april, architecture, stock</u>\n",
      "               </h3>\n",
      "           </center>\n",
      "    </li>\n",
      "    <li>\n",
      "        <h3 style=\"color:red\">Bag of Word Concept ( Unigram and Bigram modeling )</h3>\n",
      "        <center style=\"font-size:16px\"><h2><u>Algorithm</u></h2></center>\n",
      "        <!--img src=\"http://i.imgur.com/NbLEUXs.png\"-->\n",
      "        <h2>1. Text Pre-Processing</h2>\n",
      "             <h3>Same as previous</h3>\n",
      "\n",
      "        <h2>2. Text Refinement</h2>\n",
      "            <ul>\n",
      "                <h3><li>Remove all stopwords and all other irrelevant from documents</li></h3>\n",
      "                <h3><li>Tokenize documents into words</li></h3>\n",
      "                <h3><li>POS (Parts of Speech) tagging of words in document</li></h3>\n",
      "                <h3><li>Consider words whose tag is Noun, Adjective, Adverb, Verb because these words may have sentiment</li></h3>\n",
      "                <h3>\n",
      "                    <li>Extracting Phrases using this rule <br>\n",
      "                        <center><img src=\"http://i.imgur.com/NbLEUXs.png\"></center>\n",
      "                    </li>\n",
      "                </h3>\n",
      "                <h3><li>Use above phrases and words as Feature vector</li></h3>\n",
      "                <h3><li></li></h3>\n",
      "            </ul>\n",
      "        <h2>3.Learning</h2>\n",
      "            <ul>\n",
      "                <h3>\n",
      "                   <li>Normalize Count matrix of document using Tf-Idf (Term frequency\u2013Inverse document frequency) method </li>\n",
      "                </h3>\n",
      "                <h3><li>Use Naive Bayes / multinomial Naive Bayes classifier</li></h3>\n",
      "           </ul>\n",
      "           <center>\n",
      "               <h2 style=\"color:red\">Problem</h2>\n",
      "               <h3 >\n",
      "               Feature vector size  too large (about 24,000) and also content not sentimental words and phrases like..\n",
      "               <h3>\n",
      "           </center>\n",
      "           <h3>\n",
      "               <ul style=\"list-style: none\">\n",
      "                   <li>Words</li>\n",
      "                   <li>\n",
      "                       <ul style=\"color:red\">\n",
      "                           <li>current</li>\n",
      "                           <li>trial</li>\n",
      "                           <li>trick</li>\n",
      "                           <li>yummy</li>\n",
      "                           <li>android</li>\n",
      "                           <li>also</li>\n",
      "                           <li>......</li>\n",
      "                       </ul>\n",
      "                   </li>\n",
      "                   <li>Phrases</li>\n",
      "                   <li>\n",
      "                       <ul style=\"color:red\">\n",
      "                           <li>david copperfield</li>\n",
      "                           <li>computer monitor</li>\n",
      "                           <li>engine room</li>\n",
      "                           <li>time manner</li>\n",
      "                           <li>toward militariy</li>\n",
      "                           <li>......</li>\n",
      "                       </ul>\n",
      "                   </li>\n",
      "               </ul>\n",
      "               </h3>\n",
      "           \n",
      "        \n",
      "    </li>\n",
      "    <li>\n",
      "        <h3 style=\"color:green\">Enhanced version of first approach</h3>\n",
      "        <center style=\"font-size:16px\"><h2><u>Algorithm</u></h2></center>\n",
      "        ** Store a List contain positive and negative words\n",
      "        \n",
      "        <h2>1. Text Pre-Processing</h2>\n",
      "             <h3>Same as previous</h3>\n",
      "\n",
      "        <h2>2. Text Refinement</h2>\n",
      "            <ul>\n",
      "                <h3><li>Remove all stopwords and all other irrelevant from documents</li></h3>\n",
      "                <h3><li>Tokenize documents into words</li></h3>\n",
      "                <h3><li>POS (Parts of Speech) tagging of words in document</li></h3>\n",
      "                <h3><li>Consider words whose tag is Noun, Adjective, Adverb, Verb because these words may have sentiment.</li></h3>\n",
      "                <h3><li>if word in list of positive or negative consider it as feature otherwise check the objectivity of word using <br><br><u>WordNet</u>: large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms synsets.<br><br><u>SentiwordNet</u>: a lexical resource for opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores, Positive, Negative, Objective  score</li></h3>\n",
      "                <h3><li>Use words as Feature vector</li></h3>\n",
      "            </ul>\n",
      "        <h2>3.Learning</h2>\n",
      "            <ul>\n",
      "                <h3>\n",
      "                   <li>Normalize Count matrix of document using Tf-Idf (Term frequency\u2013Inverse document frequency) method </li>\n",
      "                </h3>\n",
      "                <h3><li>Use Naive Bayes / multinomial Naive Bayes classifier</li></h3>\n",
      "           </ul>\n",
      "           \n",
      "    </li>\n",
      "</ol>\n",
      "\n",
      "<center><h2><u>Result</u></h2>\n",
      "<h3>\n",
      ">>> Total Traning data: 2400 \n",
      "<table>\n",
      "    <tbody>\n",
      "        <tr>\n",
      "            <td>Accuracy %</td>\n",
      "            <td>Total Test data</td>\n",
      "            <td>Correcly predicted</td>\n",
      "            <td>Wrong Predicted</td>\n",
      "            <td>Error rate</td>\n",
      "            <td>F1 score</td>\n",
      "            <td>Precision</td>\n",
      "         </tr>\n",
      "        <tr>\n",
      "            <td>77.375</td>\n",
      "            <td>1600</td>\n",
      "            <td>1238</td>\n",
      "            <td>362</td>\n",
      "            <td>0.22625</td>\n",
      "            <td>0.7798</td>\n",
      "            <td>0.7595</td>\n",
      "        </tr>\n",
      "    </tbody>\n",
      "</table>\n",
      "</h3>\n",
      "</center>\n",
      "\n",
      "<center><h2><u>Result</u></h2>\n",
      "<h3>\n",
      ">>> Total Traning data: 2800 \n",
      "<table>\n",
      "    <tbody>\n",
      "        <tr>\n",
      "            <td>Accuracy %</td>\n",
      "            <td>Total Test data</td>\n",
      "            <td>Correcly predicted</td>\n",
      "            <td>Wrong Predicted</td>\n",
      "            <td>Error rate</td>\n",
      "            <td>F1 score</td>\n",
      "            <td>Precision</td>\n",
      "         </tr>\n",
      "        <tr>\n",
      "            <td>78</td>\n",
      "            <td>1200</td>\n",
      "            <td>936</td>\n",
      "            <td>264</td>\n",
      "            <td>0.22</td>\n",
      "            <td>0.78466</td>\n",
      "            <td>0.76837</td>\n",
      "        </tr>\n",
      "    </tbody>\n",
      "</table>\n",
      "</h3>\n",
      "</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from run import *\n",
      "labeled_reviews = get_labeled_reviews()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = []\n",
      "for cls, reviews in labeled_reviews.iteritems():\n",
      "    temp.append([cls, len(reviews[0])])\n",
      "temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[['electronics_positive', 1000],\n",
        " ['books_positive', 1000],\n",
        " ['books_negative', 1000],\n",
        " ['electronics_negative', 1000]]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3><center><b><u>Using 60% data for training and 40% for testing</u><b></center></h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_data = []\n",
      "training_label = []\n",
      "testing_data = []\n",
      "testing_label = []\n",
      "for cls, reviews in labeled_reviews.iteritems():\n",
      "    training_data = training_data + reviews[0][:600]\n",
      "    testing_data = testing_data + reviews[0][600:]\n",
      "    training_label = training_label + reviews[1][:600]\n",
      "    testing_label = testing_label + reviews[1][600:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(training_data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "2400"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(training_label)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "2400"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(testing_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "1600"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(testing_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "1600"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_testing_object = TrainingAndTesting(training_data, training_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_testing_object.train_me()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_result = train_and_testing_object.test_me(testing_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array(['positive', 'negative', 'negative', ..., 'negative', 'positive',\n",
        "       'negative'], \n",
        "      dtype='|S8')"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = TrainingAndTesting.model_evaluation(test_result, testing_label)\n",
      "final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "{'Accuracy': 0.77375,\n",
        " 'Correcly predicted': 1238,\n",
        " 'Error rate': 0.22625,\n",
        " 'Recall': 0.80125,\n",
        " 'Total Test data:': 1600,\n",
        " 'Wrong Predicted': 362,\n",
        " 'f1 score': 0.7798053527980536,\n",
        " 'precision': 0.759478672985782}"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3><center><b><u>Using 70% data for training and 30% for testing</u><b></center></h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_data = []\n",
      "training_label = []\n",
      "testing_data = []\n",
      "testing_label = []\n",
      "for cls, reviews in labeled_reviews.iteritems():\n",
      "    training_data = training_data + reviews[0][:700]\n",
      "    testing_data = testing_data + reviews[0][700:]\n",
      "    training_label = training_label + reviews[1][:700]\n",
      "    testing_label = testing_label + reviews[1][700:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_testing_object = TrainingAndTesting(training_data, training_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_testing_object.train_me()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_result = train_and_testing_object.test_me(testing_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = TrainingAndTesting.model_evaluation(test_result, testing_label)\n",
      "final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "{'Accuracy': 0.78,\n",
        " 'Correcly predicted': 936,\n",
        " 'Error rate': 0.22,\n",
        " 'Recall': 0.8016666666666666,\n",
        " 'Total Test data:': 1200,\n",
        " 'Wrong Predicted': 264,\n",
        " 'f1 score': 0.7846655791190864,\n",
        " 'precision': 0.768370607028754}"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = train_and_testing_object.get_amazon_data(query=\"python books\",  total_reviews=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_result = train_and_testing_object.test_me(d[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import array\n",
      "rating = array(d[1])\n",
      "temp = {}\n",
      "for i in xrange(len(test_result)):\n",
      "    if temp.get(str(rating[i])) is None:\n",
      "        temp[str(rating[i])] = {'positive':0, 'negative':0}\n",
      "    if test_result[i] == 'positive':\n",
      "        temp[str(rating[i])]['positive'] = temp[str(rating[i])]['positive'] + 1\n",
      "    else:\n",
      "        temp[str(rating[i])]['negative'] = temp[str(rating[i])]['negative'] + 1\n",
      "temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "{'1.0': {'negative': 6, 'positive': 0},\n",
        " '2.0': {'negative': 7, 'positive': 4},\n",
        " '3.0': {'negative': 5, 'positive': 13},\n",
        " '4.0': {'negative': 6, 'positive': 14},\n",
        " '5.0': {'negative': 4, 'positive': 32}}"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = train_and_testing_object.get_amazon_data(query=\"python books\",  total_reviews=1000)\n",
      "test_result = train_and_testing_object.test_me(d[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import array\n",
      "rating = array(d[1])\n",
      "temp = {}\n",
      "for i in xrange(len(test_result)):\n",
      "    if temp.get(str(rating[i])) is None:\n",
      "        temp[str(rating[i])] = {'positive':0, 'negative':0}\n",
      "    if test_result[i] == 'positive':\n",
      "        temp[str(rating[i])]['positive'] = temp[str(rating[i])]['positive'] + 1\n",
      "    else:\n",
      "        temp[str(rating[i])]['negative'] = temp[str(rating[i])]['negative'] + 1\n",
      "temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "{'1.0': {'negative': 30, 'positive': 6},\n",
        " '2.0': {'negative': 24, 'positive': 17},\n",
        " '3.0': {'negative': 29, 'positive': 54},\n",
        " '4.0': {'negative': 62, 'positive': 129},\n",
        " '5.0': {'negative': 73, 'positive': 477}}"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}